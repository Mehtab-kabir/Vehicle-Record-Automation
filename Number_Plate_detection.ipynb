{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDv3dIQirP8G",
        "outputId": "705ec79a-61e0-482e-efc4-89c365d030ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "x1Am9UzesHYp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from statistics import mode\n",
        "from google.colab.patches import cv2_imshow\n",
        "import easyocr\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load pre-trained YOLO model\n",
        "model = YOLO('/content/drive/MyDrive/DataScience_with_KS/Licanse_Plate_Detection/license_plate_detector.pt')\n",
        "\n",
        "# Path to your video file\n",
        "video_path = \"/content/drive/MyDrive/DataScience_with_KS/Licanse_Plate_Detection/003.mp4\"\n",
        "\n",
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])\n",
        "preds = ['']\n",
        "\n",
        "# Initialize a list to store results\n",
        "results_list = []\n",
        "\n",
        "# Read the video\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "def extract_time_from_frame(frame):\n",
        "    \"\"\"\n",
        "    Extract time from the top-right corner of the frame using OCR.\n",
        "    \"\"\"\n",
        "    time_text = \"\"\n",
        "    # Crop the top-right area (time display region)\n",
        "    time_area = frame[0:50, -300:]  # Adjust this crop area as per your video layout\n",
        "    result = reader.readtext(time_area)\n",
        "    for detection in result:\n",
        "        text = detection[1]\n",
        "        # Match time format (e.g., 09:20:25 or 09-20-25)\n",
        "        if re.search(r'\\d{2}[:\\-]\\d{2}[:\\-]\\d{2}', text):\n",
        "            time_text = text\n",
        "            break\n",
        "    return time_text, time_area\n",
        "\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break  # Exit loop when video ends\n",
        "\n",
        "    # Extract time from the current frame\n",
        "    current_time, time_area = extract_time_from_frame(frame)\n",
        "\n",
        "    # Draw a rectangle around the time area\n",
        "    cv2.rectangle(frame, (frame.shape[1] - 300, 0), (frame.shape[1], 50), (255, 0, 0), 2)\n",
        "    if current_time:\n",
        "        # Display the extracted time on the frame\n",
        "        cv2.putText(frame, current_time, (frame.shape[1] - 290, 40),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "    # Run YOLO model to detect license plates\n",
        "    results = model(frame)\n",
        "    for result in results[0].boxes.data.tolist():\n",
        "        x1, y1, x2, y2, score, class_id = result\n",
        "\n",
        "        # Draw a rectangle around the detected license plate\n",
        "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "\n",
        "        # Crop the detected license plate area\n",
        "        cr_img = frame[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "        # Perform OCR on the cropped license plate image\n",
        "        result = reader.readtext(cr_img)\n",
        "        result_time=reader.readtext(time_area)\n",
        "\n",
        "        print(result,result_time)\n",
        "        ocr_res = []\n",
        "        for k in range(len(result)):\n",
        "            if (result[k][2]) > 0.3 and len(result[k][1]) > 2:  # Confidence threshold\n",
        "                ocr_res.append(result[k][1])\n",
        "        ocr_res = ''.join(ocr_res)\n",
        "\n",
        "        # Process and display valid OCR results\n",
        "        if len(ocr_res) > 1:\n",
        "            preds.append(ocr_res.upper())\n",
        "            license_plate = mode(preds)  # Get the most frequent result so far\n",
        "\n",
        "            # Print the detected time and license plate\n",
        "            print(f\"Time: {current_time}, License Plate: {license_plate}\")\n",
        "\n",
        "            # Annotate the license plate on the frame\n",
        "            cv2.putText(frame, license_plate, (int(x1), int(y1) - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "            # Append results to the list\n",
        "            if current_time and license_plate:\n",
        "                results_list.append({\"Time\": current_time, \"License Plate\": license_plate})\n",
        "\n",
        "    # Display the frame with annotations\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "# Release the video object\n",
        "video.release()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rsivH4XXsFLR"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}